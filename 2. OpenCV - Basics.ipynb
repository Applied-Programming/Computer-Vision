{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV : Basics\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV (Open Source Computer Vision) is an image and video processing library of programming functions mainly aimed at real-time computer vision. OpenCV has bindings in C++, C, Python, Java and MATLAB/OCTAVE.\n",
    "\n",
    "**Applications** of OpenCV include variety of image and video analysis techniques like :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Egomotion\">Egomotion</a></li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Facial_recognition_system\">Facial recognition system</a></li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Gesture_recognition\">Gesture recognition</a></li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction\">Human–computer interaction</a> (HCI)</li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Mobile_robotics\">Mobile robotics</a></li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Outline_of_object_recognition\">Object Recognition</a></li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Segmentation_(image_processing)\">Image Segmentation</a> and recognition</li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Stereopsis\">Stereopsis</a> stereo vision: depth perception from 2 cameras</li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Structure_from_motion\">Structure from motion</a> (SFM)</li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Video_tracking\">Motion tracking</a></li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Augmented_reality\">Augmented reality</a></li>\n",
    "<li><a href=\"https://en.wikipedia.org/wiki/Optical_character_recognition\">Optical Character Recognition</a></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and lots of others.\n",
    "\n",
    "___\n",
    "\n",
    "In the next set of examples, we will primarily be working on Python. Installing OpenCV for python requires two main libraries, with an optional third. Below Python packages are to be downloaded and installed to their default locations.\n",
    "\n",
    "1. Python-2.7.x.\n",
    "2. Numpy.\n",
    "3. Matplotlib (Matplotlib is optional, but recommended since we use it a lot in our tutorials).\n",
    "\n",
    "## Windows Users:\n",
    "Download the appropriate wheel (.whl) file of opencv for your corresponding operating system from https://www.lfd.uci.edu/~gohlke/pythonlibs/#opencv\n",
    "\n",
    "Then open Command Prompt and direct to the Scripts folder and install the modules using pip:\n",
    ">> `C:/Python34/Scripts`\n",
    "\n",
    ">> `pip install _youropencvwhlfile_.whl`\n",
    "\n",
    ">> `pip install numpy`\n",
    "\n",
    ">> `pip install matplotlib`\n",
    "\n",
    "If this method doesn't work, here's an alternative : \n",
    "\n",
    "* Download latest OpenCV release from [here](http://sourceforge.net/projects/opencvlibrary/files/opencv-win/2.4.6/OpenCV-2.4.6.0.exe/download) and double-click to extract it.\n",
    "* Goto opencv/build/python/2.7 folder.\n",
    "* Copy cv2.pyd to C:/Python27/lib/site-packages.\n",
    "* Open Python IDLE and type following codes in Python terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "print cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the results are printed out without any errors then you have successfully installed OpenCV-Python.\n",
    "\n",
    "## Linux / Mac Users:\n",
    ">> `pip3 install numpy` or `apt-get install python3-numpy`.\n",
    "\n",
    "You may need to apt-get install python3-pip.\n",
    "\n",
    ">> `pip3 install matplotlib` or `apt-get install python3-matplotlib`.\n",
    "\n",
    ">> `apt-get install python-OpenCV`.\n",
    "\n",
    "Matplotlib is an optional choice for visualizing video or image frames . Numpy will be primarily used for its array functionality. Finally, we will be using the python-specific bindings for OpenCV called python-OpenCV.\n",
    "\n",
    "**[Here](http://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/)'s an alternative solution to build and install OpenCV in Ubuntu.**\n",
    "\n",
    "\n",
    "Once installed, Run the following python module imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are no errors then we are good to go!\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading an image:\n",
    "\n",
    "Use the function _cv2.imread()_ to read an image. The image should be in the working directory or a full path of image should be given. I highly encourage you to use your own images as examples to increase fun as well as the learning curve.\n",
    "\n",
    "Second argument is a flag which specifies the way image should be read.\n",
    "\n",
    "cv2.IMREAD_COLOR : Loads a color image. Any transparency of image will be neglected. It is the default flag.\n",
    "cv2.IMREAD_GRAYSCALE : Loads image in grayscale mode\n",
    "cv2.IMREAD_UNCHANGED : Loads image as such including alpha channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "# Load an color image in grayscale\n",
    "img = cv2.imread('images/flower.jpg',0)\n",
    "# Warning: Even if the image path is wrong, it won’t throw any error, but print img will give you None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying an image:\n",
    "Use the function _cv2.imshow()_ to display an image in a window. The window automatically fits to the image size.\n",
    "First argument is a window name which is a string. second argument is our image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GUI will open as a result and would look like:\n",
    "<img src=\"images/gray.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_cv2.waitKey()_ is a keyboard binding function. Its argument is the time in milliseconds. The function waits for\n",
    "specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed,\n",
    "it waits indefinitely for a key stroke. It can also be set to detect specific key strokes like, if key a is pressed etc which\n",
    "we will discuss below.\n",
    "\n",
    "_cv2.destroyAllWindows()_ simply destroys all the windows we created. If you want to destroy any specific window,\n",
    "use the function cv2.destroyWindow() where you pass the exact window name as the argument.\n",
    "\n",
    "Note: There is a special case where you can already create a window and load image to it later. In that case, you can\n",
    "specify whether window is resizable or not. It is done with the function cv2.namedWindow(). By default, the flag is\n",
    "cv2.WINDOW_AUTOSIZE. But if you specify flag to be cv2.WINDOW_NORMAL, you can resize window. It will be\n",
    "helpful when image is too large in dimension and adding track bar to windows.\n",
    "\n",
    "This can be done using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write an image\n",
    "Use the function _cv2.imwrite()_ to save an image.\n",
    "First argument is the file name, second argument is the image you want to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('flowergray.png',img)\n",
    "# This will save the image in PNG format in the working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Getting started with Videos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV provides a very simple interface to capture live stream with our own cameras. \n",
    "\n",
    "To capture a video, you need to create a VideoCapture object. Its argument can be either the device index or the name\n",
    "of a video file. Device index is just the number to specify which camera. \n",
    "If there are multiple cameras connected to your computer passing index as 0 or -1 would start the first camera; passing 1 as index would start the second camera and so on.\n",
    "\n",
    "After starting the respective camera, you can capture frame-by-frame. And at the end of capturing, we release the capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will capture a\n",
    "video from the camera (in this case the in-built webcam of my laptop), convert it into grayscale video and display it.\n",
    "\n",
    "cap.read() returns a bool (True/False). If frame is read correctly, it will be True. So you can check end of the\n",
    "video by checking this return value.\n",
    "Sometimes, cap may not have initialized the capture. In that case, this code shows error. You can check whether it is\n",
    "initialized or not by the method cap.isOpened(). If it is True, OK. Otherwise open it using cap.open()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing Video from file\n",
    "It is same as capturing from Camera, just change camera index with video file name. Also while displaying the frame,\n",
    "use appropriate time for _cv2.waitKey()_. If it is too less, video will be very fast and if it is too high, video will be\n",
    "slow (Well, that is how you can display videos in slow motion). 25 milliseconds will be OK in normal cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture('videos/people-walking.mp4')\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a Video\n",
    "What if we want to save the video after we capture it and process it frame-by-frame? For images, it is very simple, just\n",
    "use cv2.imwrite().\n",
    "\n",
    "This time we create a VideoWriter object. We should specify the output file name (eg: output.avi). Then we should\n",
    "specify the FourCC code . Then number of frames per second (fps) and frame size should\n",
    "be passed. And last one is isColor flag. If it is True, encoder expect color frame, otherwise it works with grayscale\n",
    "frame.\n",
    "\n",
    "FourCC is a 4-byte code used to specify the video codec. The list of available codes can be found in fourcc.org. It is\n",
    "platform dependent.\n",
    "\n",
    "FourCC code is passed as cv2.VideoWriter_fourcc(’M’,’J’,’P’,’G’) or\n",
    "cv2.VideoWriter_fourcc(*’MJPG) for MJPG.\n",
    "\n",
    "Below code captures from a Camera, flip every frame in vertical direction and saves it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        frame = cv2.flip(frame,0)\n",
    "        # write the flipped frame\n",
    "        out.write(frame)\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing and Writing Text on Images\n",
    "To draw different shapes using OpenCV we would be using functions like:\n",
    "_cv2.line(), cv2.circle() , cv2.rectangle(), cv2.ellipse() etc\n",
    "\n",
    "In all the above functions, you will see some common arguments as given below:\n",
    "* img : The image where you want to draw the shapes\n",
    "* color : Color of the shape. for BGR, pass it as a tuple, eg: (255,0,0) for blue. For grayscale, just pass the scalar value.\n",
    "* thickness : Thickness of the line or circle etc. If -1 is passed for closed figures like circles, it will fill the shape. default thickness = 1\n",
    "* lineType : Type of line, whether 8-connected, anti-aliased line etc. By default, it is 8-connected. cv2.LINE_AA gives anti-aliased line which looks great for curves.\n",
    "\n",
    "To add text to images you need to specify following things:\n",
    "* Text data that you want to write \n",
    "* Position coordinates of where you want put it (i.e. bottom-left corner where data starts). \n",
    "* Font type (Check cv2.putText() docs for supported fonts)\n",
    "* Font Scale (specifies the size of font)\n",
    "* regular things like color, thickness, lineType etc. For better look, lineType = cv2.LINE_AA is recommended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('images/flower.jpg',cv2.IMREAD_COLOR)\n",
    "\n",
    "cv2.line(img,(0,0),(150,150),(255,255,255),15)  # line\n",
    "# To draw a line, you need to pass starting and ending coordinates of line.\n",
    "\n",
    "cv2.rectangle(img,(15,25),(200,150),(0,0,255),15)  # red rect \n",
    "# To draw a rectangle, you need top-left corner and bottom-right corner of rectangle.\n",
    "\n",
    "cv2.circle(img,(100,63), 55, (0,255,0), -1)  #circle\n",
    "# To draw a circle, you need its center coordinates and radius.\n",
    "\n",
    "cv2.ellipse(img,(256,256),(100,50),0,0,180,255,-1) #elipse\n",
    "# To draw the ellipse, we need to pass follwing arguments : 1.center location (x,y); 2.axes lengths (major axis length, minor axis length).\n",
    "# then the angle of rotation of ellipse in anti-clockwise direction.\n",
    "# startAngle and endAngle denotes the starting and ending of ellipse arc measured in clockwise direction from major axis.\n",
    "# i.e. giving values 0 and 360 gives the full ellipse\n",
    "\n",
    "pts = np.array([[10,5],[20,30],[70,20],[50,10]], np.int32) # polygon\n",
    "# To draw a polygon, first you need coordinates of vertices. Make those points into an array of shape ROWSx1x2 where\n",
    "# ROWS are number of vertices and it should be of type int32.\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv2.polylines(img, [pts], True, (0,255,255), 3)\n",
    "\n",
    "# writing\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,'Text!',(0,130), font, 1, (200,255,155), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output would be : \n",
    "<img src=\"captures/shapesntext.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Mouse as a Paint Brush:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a simple application which draws a circle on an image wherever we double-click on it.\n",
    "\n",
    "First we create a mouse callback function which is executed when a mouse event take place. Mouse event can be\n",
    "anything related to mouse like left-button down, left-button up, left-button double-click etc. It gives us the coordinates\n",
    "(x,y) for every mouse event. With this event and location, we can do whatever we like. To list all available events\n",
    "available, run the following code in Python terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EVENT_FLAG_ALTKEY', 'EVENT_FLAG_CTRLKEY', 'EVENT_FLAG_LBUTTON', 'EVENT_FLAG_MBUTTON', 'EVENT_FLAG_RBUTTON', 'EVENT_FLAG_SHIFTKEY', 'EVENT_LBUTTONDBLCLK', 'EVENT_LBUTTONDOWN', 'EVENT_LBUTTONUP', 'EVENT_MBUTTONDBLCLK', 'EVENT_MBUTTONDOWN', 'EVENT_MBUTTONUP', 'EVENT_MOUSEHWHEEL', 'EVENT_MOUSEMOVE', 'EVENT_MOUSEWHEEL', 'EVENT_RBUTTONDBLCLK', 'EVENT_RBUTTONDOWN', 'EVENT_RBUTTONUP']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "events = [i for i in dir(cv2) if 'EVENT' in i]\n",
    "print events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating mouse callback function has a specific format which is same everywhere. It differs only in what the function\n",
    "does. So our mouse callback function does one thing, it draws a circle where we double-click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        cv2.circle(img,(x,y),100,(255,0,0),-1)\n",
    "        \n",
    "# Create a black image, a window and bind the function to window\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',draw_circle)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    if cv2.waitKey(20) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go for much more better application. In this, we draw either rectangles or circles (depending on the mode we\n",
    "select) by dragging the mouse like we do in Paint application. So our mouse callback function has two parts, one to\n",
    "draw rectangle and other to draw the circles. This specific example will be really helpful in creating and understanding\n",
    "some interactive applications like object tracking, image segmentation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "drawing = False # true if mouse is pressed\n",
    "mode = True # if True, draw rectangle. Press 'm' to toggle to curve\n",
    "ix,iy = -1,-1\n",
    "# mouse callback function\n",
    "def draw_circle(event,x,y,flags,param):\n",
    "    global ix,iy,drawing,mode\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix,iy = x,y\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            if mode == True:\n",
    "                cv2.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "            else:\n",
    "                cv2.circle(img,(x,y),5,(0,0,255),-1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if mode == True:\n",
    "            cv2.rectangle(img,(ix,iy),(x,y),(0,255,0),-1)\n",
    "        else:\n",
    "            cv2.circle(img,(x,y),5,(0,0,255),-1)\n",
    "# Next we have to bind this mouse callback function to OpenCV window. In the main loop, we should set a keyboard binding for key ‘m’ to toggle between rectangle and circle.        \n",
    "\n",
    "img = np.zeros((512,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',draw_circle)\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('m'):\n",
    "        mode = not mode\n",
    "    elif k == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trackbar as the Color Palette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create a simple application which shows the color you specify. You have a window which shows the\n",
    "color and three trackbars to specify each of B,G,R colors. You slide the trackbar and correspondingly window color\n",
    "changes. By default, initial color will be set to Black.\n",
    "\n",
    "For _cv2.getTrackbarPos()_ function, first argument is the trackbar name, second one is the window name to which it is\n",
    "attached, third argument is the default value, fourth one is the maximum value and fifth one is the callback function which is executed everytime trackbar value changes. The callback function always has a default argument which is\n",
    "the trackbar position. In our case, function does nothing, so we simply pass.\n",
    "\n",
    "Another important application of trackbar is to use it as a button or switch. OpenCV, by default, doesn’t have button\n",
    "functionality. So you can use trackbar to get such functionality. In our application, we have created one switch in\n",
    "which application works only if switch is ON, otherwise screen is always black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('R','image',0,255,nothing)\n",
    "cv2.createTrackbar('G','image',0,255,nothing)\n",
    "cv2.createTrackbar('B','image',0,255,nothing)\n",
    "\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    # get current positions of four trackbars\n",
    "    r = cv2.getTrackbarPos('R','image')\n",
    "    g = cv2.getTrackbarPos('G','image')\n",
    "    b = cv2.getTrackbarPos('B','image')\n",
    "    s = cv2.getTrackbarPos(switch,'image')\n",
    "    \n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "        \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our application would look something like this:\n",
    "\n",
    "<img src=\"captures/trackbar.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
